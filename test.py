# -*- coding: utf-8 -*-
"""Test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D9augTsIwkyHlbuzFxlTUI7nH-y-Mo00?usp=sharing
    Developer: Prithvi Mulpuri
    Version: 1.0
"""


# Commented out IPython magic to ensure Python compatibility.
#Install pacakages: pandas & unidecode
# pip install Unidecode

# Importing libraries
import sys
import pandas as pd
import csv 
import json 
import io
import unidecode

# Task 1 - Input a CSV file and convert it to JSON
# Function to convert a CSV to JSON 
# Takes the file paths as arguments


def make_json(csvFilePath, jsonFilePath): 
	
	# create a dictionary 
	data = {} 
	
	# Open a csv reader called DictReader 
	with open(csvFilePath, encoding='utf-8') as csvf: 
		csvReader = csv.DictReader(csvf) 
		
		# Convert each row into a dictionary 
		# and add it to data 
		for rows in csvReader: 
			
			# Assuming a column named 'user_pseudo_id' to 
			# be the primary key 
			key = rows['user_pseudo_id'] 
			data[key] = rows 

	# Open a json writer, and use the json.dumps() 
	# function to dump data 
	with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: 
		jsonf.write(json.dumps(data, indent=4)) 
		
# Driver Code 
# Decide the two file paths according to your 
# computer system 
jsonFilePath = "D:/Downloads/sandbox-installs.json"

#Task 2 - Input a CSV file and present a data summary

def DisplayDataSumarry(csvFilePath):
  #Data Cleaning
  sample_data = pd.read_csv(csvFilePath)

  #As these language codes cannot be clearly determined they have been replaced by 'Other_Language'.

  sample_data['device_language'] = sample_data['device_language'].replace([
    'ar-', 'en-', 'pt-', 'zz-zz', 'en-','pt-' ], 'Other_Language')

  #Undertermined install sources have been replaced by Other_Source

  sample_data['install_source'] = sample_data['install_source'].replace(['97','181', '1051',
  '1048' '140', '68', '158', '1168', '409', 'æµè§ˆå™¨', '313', '104', '24', '21', '22', '19',
  '866', '2', '19', '21', '22', '24', '30', '68', '97', '104', '303', '409','è‘«èŠ¦ä¾'], 'Other_Source')

  #Data summary
  DataSummary = sample_data

  cols = ['geo_country',	'geo_region',	'geo_city',	'install_source',	'ua_name'	, 'ua_medium',	'ua_source',	'device_category',	'device_brand_name',	'device_model_name',	'device_os_hardware_model',	'device_os',	'device_os_version', 'is_limited_ad_tracking',	'device_language']
  DataSummary[cols]

  
  return DataSummary[cols].describe()


#Task 3 - Input a CSV file and generate a SQL insert statement for all rows in the input
def sql_statement_gen(outputpath = str, tabname = str, csvFilePath = str):
  sample_data = pd.read_csv(csvFilePath)
  df = sample_data
  with io.open(outputpath, "w", encoding='utf-8'):
    for index, row in df.iterrows():
      print('INSERT INTO ' + tabname + '(\'user_pseudo_id\',\'sku\',\'app_version\',\'geo_country\',\'geo_region\',\'geo_city\',\'install_source\',\'ua_name\',\'ua_medium\' ,\'ua_source\',\'device_category\',\'device_brand_name\',\'device_model_name\',\'device_os_hardware_model\',\'device_os\',\'device_os_version\',\'idfa\',\'idfv\',\'is_limited_ad_tracking\',\'device_language\',\'device_time_zone_offset\',\'timestamp_raw\',\'table_date\',\'is_returning_user\',\'session_id)\') VALUES (',row['user_pseudo_id'],',',row['sku'],',',row['app_version'],',',row.astype(str)['geo_country'],',',row.astype(str)['geo_region'],',',row.astype(str)['geo_city'],',',row.astype(str)['install_source'],',', row.astype(str)['ua_name'],',', row.astype(str)['ua_medium'],',', row.astype(str)['ua_source'],',', row.astype(str)['device_category'],',',row.astype(str)['device_brand_name'],',', row.astype(str)['device_model_name'],',',	row.astype(str)['device_os_hardware_model'],',', row.astype(str)['device_os'],',',row['device_os_version'],',',row.astype(str)['idfa'],',',row.astype(str)['idfv'],',', row.astype(str)['is_limited_ad_tracking'],',',row.astype(str)['device_language'],',',row.astype(str)['device_time_zone_offset'],',', row.astype(str)['timestamp_raw'],',', row.astype(str)['table_date'],',', row.astype(str)['is_returning_user'],',\''+row.astype(str)['session_id']+'\');', file=open(outputpath, "a", encoding='utf-8'))
  return


#Main function to run all the 3 tasks
if __name__ == "__main__":
    csvFilePath = input("please enter csv file path : ")
    jsonFilePath = input("please enter json file path : ")
    make_json(csvFilePath,jsonFilePath)
    print("JSON file has been generated successfully")
    csv_file = input("Please Enter csv file name : ")
    Disp = DisplayDataSumarry(csv_file)
    print("--------------------------------------------------Data Summary-------------------------------------")
    print(Disp)
    sql_statement_gen(outputpath = outputpath, tabname="DataSum", csvFilePath = csvFilePath)
    outputpath = input("please enter output.txt file path to save sql insert statements : ")
    sql_statement_gen(outputpath = outputpath, tabname="DataSum", csvFilePath = csvFilePath)
    print("sql insert statements output file has been successfully generated")
    print("sql insert statement output file has been successfully generated")
    